Inspiration and Context
The inspiration for this project came from browsing the r/Python subreddit, a great community to see what others are building with Python and to stay updated on Python news. One post asked if anyone had completely automated their job using Python.

Many people have successfully automated their jobs, especially data entry roles, by using Python with tools like Beautiful Soup and Selenium. These jobs often involve moving data from one format to another, making them ideal for automation.

If you find a remote data entry job, for example on Indeed.com, you can start by doing the work manually. Once you understand the tasks, such as gathering statistical data, preparing reports, and maintaining spreadsheets, you can automate a large portion of the job with Python. This could allow you to complete 70% of your work automatically while still being paid as a full-time employee.

Project Overview
In this project, we will tackle a research data entry job involving house prices that meet specific criteria for a client on the Zillow website. The data will then be transferred into a form that creates a Google Sheets spreadsheet.

Summary of the Task
The first part of the project involves scraping relevant listings using Beautiful Soup. The second part involves filling out the Google Form using Selenium.

Once you are ready, proceed to the next lesson to review the project requirements and begin the Capstone project.

Key Takeaways
The Capstone project focuses on automating a data entry job using web scraping techniques.
The project involves scraping house rental data from a Zillow clone website using Beautiful Soup.
Selenium will be used to automatically fill out a Google Form with the scraped data.
This project combines skills learned in web scraping with Beautiful Soup and Selenium to create a practical automation solution.
